Q.1. Write a python program to implement Polynomial Linear Regression for
Boston Housing Dataset.
Ans:
# Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score
# Step 1: Load your dataset from CSV file
# Replace 'path_to_your_file.csv' with the actual path to your dataset
df = pd.read_csv('path_to_your_file.csv')
# Step 2: Display the first few rows of the dataset to understand its structure
print("\nDataset Preview:")
print(df.head())
# Step 3: Check for null values and handle them (if necessary)
print("\nChecking for null values...")
print(df.isnull().sum())
X = df.iloc[:, :-1].values  # Features (all columns except the last one)
y = df.iloc[:, -1].values   # Target (last column)
# Step 5: Split the dataset into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Step 6: Create Polynomial Features (degree=2, can experiment with higher degrees)
poly = PolynomialFeatures(degree=2)  # You can change the degree as needed
X_train_poly = poly.fit_transform(X_train)  # Transform the training set to polynomial features
X_test_poly = poly.transform(X_test)  # Transform the test set to polynomial features
# Step 7: Initialize the Linear Regression model
model = LinearRegression()
# Step 8: Train the model on the polynomial features
model.fit(X_train_poly, y_train)
# Step 9: Make predictions on the test set
y_pred = model.predict(X_test_poly)
# Step 10: Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"\nMean Squared Error: {mse}")
print(f"R^2 Score: {r2}")
# Displaying actual vs predicted values for comparison
print("\nPredictions vs Actual values:")
for i in range(len(y_test)):
    print(f"Predicted: {y_pred[i]:.2f}, Actual: {y_test[i]:.2f}")

Q2. Use K-means clustering model and classify the employees into
various income groups or clusters. Preprocess data if require (i.e. drop
missing or null values). Use elbow method and Silhouette Score to find
value of k.
Ans:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
# Generate a sample dataset (replace this with your actual dataset)
np.random.seed(42)
data = {
'EmployeeID': range(1, 101),
'Age': np.random.randint(20, 60, size=100),
'Income': np.random.randint(30000, 120000, size=100),
'YearsAtCompany': np.random.randint(1, 30, size=100)
}
df = pd.DataFrame(data)
# Check for missing values
print("Missing values in each column:")
print(df.isnull().sum())
# Drop missing values if any (for this example, there are none)
df.dropna(inplace=True)
# Features to be used for clustering
features = df[['Age', 'Income', 'YearsAtCompany']]
# Standardize the features
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)
# Determine the optimal number of clusters using the elbow method
inertia = []
silhouette_scores = []
for k in range(2, 11):
kmeans = KMeans(n_clusters=k, random_state=42)
kmeans.fit(features_scaled)
inertia.append(kmeans.inertia_)
silhouette_scores.append(silhouette_score(features_scaled,
kmeans.labels_))
# Plot the elbow method results
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(range(2, 11), inertia, marker='o')
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of clusters (k)')
plt.ylabel('Inertia')
# Plot Silhouette Scores
plt.subplot(1, 2, 2)
plt.plot(range(2, 11), silhouette_scores, marker='o')
plt.title('Silhouette Score for Optimal k')
plt.xlabel('Number of clusters (k)')
plt.ylabel('Silhouette Score')
plt.tight_layout()
plt.show()
# Choose the optimal number of clusters based on elbow method and
silhouette score
optimal_k = 4 # You may adjust this based on the plots
# Fit KMeans with the optimal number of clusters
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
df['Cluster'] = kmeans.fit_predict(features_scaled)
# Display the clustered data
print("\nClustered Employee Data:")
print(df.head())
# Display cluster centers
cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)
print("\nCluster Centers (in original scale):")
print(cluster_centers)
