Q.1. Write a python program to implement Multiple Linear Regression for Fuel Consumption
dataset.
Ans:
# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
# Load the dataset (replace 'path_to_fuel_consumption.csv' with the actual path)
dataset = pd.read_csv('path_to_fuel_consumption.csv')
# Display initial data information
print("Initial Dataset Information:")
print(dataset.info())
# Step 1: Check for null values and remove rows with null values
print("\nChecking for null values...")
print(dataset.isnull().sum())
# Remove rows with any null values
dataset = dataset.dropna()
print("\nDataset after removing null values:")
print(dataset.info())
# Step 2: Select the independent variables (features) and the dependent variable (target)
# Assuming the features are 'engine_size', 'weight', and 'year', and target is 'fuel_consumption'
X = dataset[['engine_size', 'weight', 'year']]  # Features
y = dataset['fuel_consumption']  # Target variable
# Step 3: Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Step 4: Initialize and train the Multiple Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)
# Step 5: Predict on the test set
y_pred = model.predict(X_test)
# Step 6: Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("\nModel Evaluation:")
print(f"Mean Squared Error: {mse}")
print(f"R^2 Score: {r2}")
# Displaying prediction results
print("\nPredictions on test set:")
for i in range(len(X_test)):
    print(f"Predicted Fuel Consumption: {y_pred[i]:.2f}, Actual Fuel Consumption: {y_test.iloc[i]:.2f}")

Q.2. Write a python program to implement k-nearest Neighbors ML algorithm to build
prediction model (Use iris Dataset)
Ans
# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
# Step 1: Load the dataset from a CSV file
# Replace 'path_to_your_file.csv' with the actual path to your dataset
dataset = pd.read_csv('path_to_your_file.csv')
# Display initial dataset information
print("Dataset Information:")
print(dataset.info())
# Step 2: Check for null values and remove them (if any)
print("\nChecking for null values...")
print(dataset.isnull().sum())
# Remove rows with null values (if necessary)
dataset = dataset.dropna()
# Step 3: Split the dataset into features (X) and target (y)
# Assuming the target variable (label) is in the last column, adjust if necessary
X = dataset.iloc[:, :-1]  # All columns except the last (features)
y = dataset.iloc[:, -1]   # Last column (target)
# Step 4: Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Step 5: Initialize the KNeighborsClassifier
# Use k=3 for simplicity, can experiment with other values for k
knn = KNeighborsClassifier(n_neighbors=3)
# Step 6: Train the KNN model
knn.fit(X_train, y_train)
# Step 7: Make predictions on the test set
y_pred = knn.predict(X_test)
# Step 8: Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"\nAccuracy of the K-Nearest Neighbors model: {accuracy * 100:.2f}%")
# Displaying predictions vs actual values
print("\nPredictions vs Actual values:")
for i in range(len(y_test)):
    print(f"Predicted: {y_pred[i]}, Actual: {y_test.iloc[i]}")
