Q1. Write a python program to implement Polynomial Regression for Boston Housing Dataset.
Ans:
# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
# Step 1: Load the dataset from CSV
# Replace 'boston_housing.csv' with your actual file path
df = pd.read_csv('boston_housing.csv')
# Step 2: Preview the dataset (optional)
print("\nDataset Preview:")
print(df.head())
# Step 3: Preprocess the data# Check for missing values
print("\nChecking for missing values...")
print(df.isnull().sum())
# If any missing values exist, handle them (e.g., by dropping or filling)
df = df.dropna()  # Dropping rows with missing values (alternatively, use fillna())
# Step 4: Select features (X) and target variable (y)
# Assuming 'Price' is the target variable and the rest are features
X = df.drop('Price', axis=1)  # Features (independent variables)
y = df['Price']  # Target variable (dependent variable)
# Step 5: Split the dataset into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Step 6: Apply Polynomial Feature Transformation
# Here, we'll use a degree of 2 (quadratic), but you can increase the degree if needed.
poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(X_train)  # Transforming training data
X_test_poly = poly.transform(X_test)  # Transforming testing data
# Step 7: Initialize the Linear Regression model
model = LinearRegression()
# Step 8: Train the model
model.fit(X_train_poly, y_train)
# Step 9: Make predictions on the test set
y_pred = model.predict(X_test_poly)
# Step 10: Evaluate the model performance
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
# Step 11: Print the results
print(f"\nMean Squared Error: {mse}")
print(f"R-squared: {r2}")
# Optional: Visualize the results for a single feature (for demonstration)
plt.scatter(X_test.iloc[:, 0], y_test, color='blue', label='Actual')  # Actual prices (for the first feature)
plt.scatter(X_test.iloc[:, 0], y_pred, color='red', label='Predicted')  # Predicted prices (for the first feature)
plt.title('Polynomial Regression (Boston Housing)')
plt.xlabel('Feature: (First feature in dataset)')
plt.ylabel('House Price')
plt.legend()
plt.show()
