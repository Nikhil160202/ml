Q1. Write a python program to implement Polynomial Regression for Boston Housing Dataset.
Ans:
# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
# Step 1: Load the dataset from CSV
# Replace 'boston_housing.csv' with your actual file path
df = pd.read_csv('boston_housing.csv')
# Step 2: Preview the dataset (optional)
print("\nDataset Preview:")
print(df.head())
# Step 3: Preprocess the data# Check for missing values
print("\nChecking for missing values...")
print(df.isnull().sum())
# If any missing values exist, handle them (e.g., by dropping or filling)
df = df.dropna()  # Dropping rows with missing values (alternatively, use fillna())
# Step 4: Select features (X) and target variable (y)
# Assuming 'Price' is the target variable and the rest are features
X = df.drop('Price', axis=1)  # Features (independent variables)
y = df['Price']  # Target variable (dependent variable)
# Step 5: Split the dataset into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Step 6: Apply Polynomial Feature Transformation
# Here, we'll use a degree of 2 (quadratic), but you can increase the degree if needed.
poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(X_train)  # Transforming training data
X_test_poly = poly.transform(X_test)  # Transforming testing data
# Step 7: Initialize the Linear Regression model
model = LinearRegression()
# Step 8: Train the model
model.fit(X_train_poly, y_train)
# Step 9: Make predictions on the test set
y_pred = model.predict(X_test_poly)
# Step 10: Evaluate the model performance
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
# Step 11: Print the results
print(f"\nMean Squared Error: {mse}")
print(f"R-squared: {r2}")
# Optional: Visualize the results for a single feature (for demonstration)
plt.scatter(X_test.iloc[:, 0], y_test, color='blue', label='Actual')  # Actual prices (for the first feature)
plt.scatter(X_test.iloc[:, 0], y_pred, color='red', label='Predicted')  # Predicted prices (for the first feature)
plt.title('Polynomial Regression (Boston Housing)')
plt.xlabel('Feature: (First feature in dataset)')
plt.ylabel('House Price')
plt.legend()
plt.show()

Q.2. Write a python program to Implement Decision Tree classifier model on Data which
is extracted from images that were taken from genuine and forged banknote-like
specimens.
Ans:
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report,
confusion_matrix
import numpy as np
# Load the dataset
data = pd.read_csv("C:/Users/PC
04/Downloads/data_banknote_authentication.txt")
# Assign column names (these names should correspond to the dataset's
attributes)
data.columns = ['Variance', 'Skewness', 'Curtosis', 'Entropy', 'Class']
# Display the first few rows of the dataset
print("Dataset Preview:")
print(data.head())
# Assign column names (these names should correspond to the dataset's
attributes)
data.columns = ['Variance', 'Skewness', 'Curtosis', 'Entropy', 'Class']
# Display the first few rows of the dataset
print("Dataset Preview:")
print(data.head())
# Split the dataset into features and labels
X = data[['Variance', 'Skewness', 'Curtosis', 'Entropy']]
y = data['Class'] # Labels
# Features
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,
random_state=42)
# Create the Decision Tree classifier
dt_classifier = DecisionTreeClassifier()
# Fit the model on the training data
dt_classifier.fit(X_train, y_train)
# Make predictions on the test data
y_pred = dt_classifier.predict(X_test)
# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)
# Display the evaluation metrics
print(f"Accuracy: {accuracy:.2f}")
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(class_report)
# Optional: Save the model if needed for future use
import joblib
joblib.dump(dt_classifier, 'decision_tree_model.joblib')
print("Decision Tree model saved as 'decision_tree_model.joblib'")
